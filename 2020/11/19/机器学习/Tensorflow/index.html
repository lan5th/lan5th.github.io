<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lan5th.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="1import tensorflow as tf								导入tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow2.0">
<meta property="og:url" content="http://lan5th.github.io/2020/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow/index.html">
<meta property="og:site_name" content="Lzone">
<meta property="og:description" content="1import tensorflow as tf								导入tensorflow">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/lan5th/pics/blog_images/image-20201221104752364.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/Nxp5XbZOtnaql9W.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/DIXJaLF2lEcWH1R.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/YAXDR6zK9JVFswZ.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/RCuek7PGmlYi9dt.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/hIBvDdnt72wNL3W.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/DdpIyYWfaXA5xh1.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/LyxnkhZBW5zN7JD.png">
<meta property="og:image" content="https://i.loli.net/2020/11/19/6snpNe8GCmvj7I9.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/ScVf1xabOjqnoXF.png">
<meta property="og:image" content="https://i.loli.net/2020/11/19/AbBgPzp32NdOSkW.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/qxAvKV3mgzO8tbH.png">
<meta property="og:image" content="https://i.loli.net/2020/11/19/ZrLTUHJi6PFQtB7.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/pf2iakB6LUATunb.png">
<meta property="og:image" content="https://i.loli.net/2020/11/20/VgTpCzkEPYJKGIn.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/hixnQZJ365IbyFK.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/whT9eGHlLZqRkEC.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/O8Re3jfX2nC7kQq.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/3esCl2RQxMFTpNq.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/ybqoa5lWQA9vghF.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/HBxnvPEhOjg4aRF.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/tjugIfeDqPkO7sV.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/rfJIpYXoU718d4c.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/So4DFhWf3BwrV9A.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/fpkcAGlVC2FIz8Z.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/qAmVlzCeFUaQodg.png">
<meta property="og:image" content="https://i.loli.net/2020/12/21/H2JcEDCTWRgGMkP.png">
<meta property="og:image" content="https://i.loli.net/2020/12/22/dhiJTE7Y61LbGMU.png">
<meta property="og:image" content="https://i.loli.net/2020/12/22/6xrMUNYS4Pgdbhf.png">
<meta property="og:image" content="https://i.loli.net/2020/12/22/wkdYRCqVHcMOuxA.png">
<meta property="og:image" content="https://i.loli.net/2020/12/22/mKfH5dh6pvRkBMq.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/lan5th/pics/blog_images/image-20201223095033595.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/jh5svyZizwU4Rx2.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/ImxZkehCEloinvP.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/FiPRgWhA7ubK2EV.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/vqFpwWurBDbJXmf.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/wvumgzbaKsHAhpy.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/VytBqKxFHUmDpEX.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/q4PLidCgnhoWKtT.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/tgZc7Av5HXTGfyw.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/EaBp62TIdDwPRYo.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/YZOxBVvSa16U9Io.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/lP1OcHYXnIqwJa5.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/jrHPGopIh7u31ls.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/velEPCKORxoDa4t.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/8wpHBLQCaIGrMWP.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/yt1NViczEWI8lOh.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/b3cpo8GSkNghlaD.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/5q1iUBLj6TxAcvK.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/i5VR2LlcdC6vmJG.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/XQNSZ9jyhtPkIHr.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/LHRhbPFYeCrzmT7.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/FEgqiMYczfCX4Wy.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/fdwJ2xPZGXRmehB.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/Qm6tfnDTAlvaWyr.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-206db7ba9d32a80ff56b6cc988a62440_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-b0175ebd3419f9a11a3d0d8b00e28675_720w.jpg">
<meta property="og:image" content="https://i.loli.net/2020/12/23/Znw1AJ2cg3XTsjb.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/oPOfDW2NdQBzxMm.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/d3lPqfMxOe8Wchi.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/zAJreZmMOqx7cy1.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/MPFSDNvqnETO3bh.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/spUmoR86BkyFIQ1.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/ajo3ZFGWKPwzvB9.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/bfMZFEv41rGxOeY.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/2pmQUrVJ96hPbRL.png">
<meta property="og:image" content="https://i.loli.net/2020/12/23/QmLoOwrtcKBqb2X.png">
<meta property="article:published_time" content="2020-11-18T16:19:14.401Z">
<meta property="article:modified_time" content="2021-03-11T15:21:08.910Z">
<meta property="article:author" content="lan5th">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/lan5th/pics/blog_images/image-20201221104752364.png">

<link rel="canonical" href="http://lan5th.github.io/2020/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Tensorflow2.0 | Lzone</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  
  
    <script
      src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4="
      crossorigin="anonymous"></script>
    <script src="/js/cursor/text.js"></script>
  

<link rel="alternate" href="/atom.xml" title="Lzone" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzone</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">always be doing</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/lan5th" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://lan5th.github.io/2020/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="lan5th">
      <meta itemprop="description" content="practise more">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzone">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Tensorflow2.0
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-19 00:19:14" itemprop="dateCreated datePublished" datetime="2020-11-19T00:19:14+08:00">2020-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-03-11 23:21:08" itemprop="dateModified" datetime="2021-03-11T23:21:08+08:00">2021-03-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>30k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>27 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf								导入tensorflow</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<p>Tensorflow学习代码</p>
<p>链接：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1LJM8_QoT-Z88VYwZhSonFw">https://pan.baidu.com/s/1LJM8_QoT-Z88VYwZhSonFw</a><br>提取码：ammg </p>
<h2 id="Tensor数据"><a href="#Tensor数据" class="headerlink" title="Tensor数据"></a>Tensor数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">list</span><br><span class="line">np.array科学计算库</span><br><span class="line">tf.Tensor支持连续求导</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/lan5th/pics/blog_images/image-20201221104752364.png" alt="image-20201221104752364"></p>
<h3 id="创建tensor"><a href="#创建tensor" class="headerlink" title="创建tensor"></a>创建tensor</h3><p><code>tf.constant([1,5], dtype=tf.int64)</code>创建一个tensor</p>
<p><code>tf.convert_to_tensor(np, dtype=tf.int64)</code>可以将numpy数据转换为tensor</p>
<p><img src="https://i.loli.net/2020/12/21/Nxp5XbZOtnaql9W.png" alt="image-20201221110137328"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.constant([1,5], dtype&#x3D;tf.int64)创建一个张量</span><br><span class="line">tf.convert_to_tensor(np, dtype&#x3D;tf.int64)将numpy数据转换为tensor</span><br><span class="line">tf.zeros(维度)创建全为0的tensor</span><br><span class="line">tf.ones(维度)创建全为0的tensor</span><br><span class="line">tf.fill(维度, 指定值)创建全为指定值的tensor</span><br><span class="line">tf.random.normal(维度, mean&#x3D;, stddev&#x3D;)创建指定维度的正态分布随机数</span><br><span class="line">tf.random.truncated_normal(维度, mean&#x3D;, stddev&#x3D;)创建指定维度的正态分布随机数,其中所有数值都在(μ-2σ,μ+2σ)范围内</span><br><span class="line">tf.uniform(维度,minval&#x3D;,maxval)生成指定维度均匀分布的随机数</span><br></pre></td></tr></table></figure>

<h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.cast(tf, dtype&#x3D;)强制转换tensor中的数据类型</span><br><span class="line">tf.reduce_min(tf)计算最小值</span><br><span class="line">tf.reduce_max(tf)计算最大值</span><br><span class="line">tf.reduce_mean(tf, axis&#x3D;)计算指定经度的平均值(不指定axis则对所有数据进行操作)</span><br><span class="line">tf.reduce_sum(tf, axis&#x3D;)计算指定经度的和(不指定axis则对所有数据进行操作)</span><br><span class="line">tf.Variable(tf)将变量标记为可训练，变量在反向传播中记录梯度信息</span><br><span class="line">其他数学运算如下图</span><br></pre></td></tr></table></figure>

<p>维度相同的tensor才能进行数学运算</p>
<p><img src="https://i.loli.net/2020/12/21/DIXJaLF2lEcWH1R.png" alt="image-20201221111649506"></p>
<h6 id="axis"><a href="#axis" class="headerlink" title="axis"></a>axis</h6><p><img src="https://i.loli.net/2020/12/21/YAXDR6zK9JVFswZ.png" alt="image-20201221111145138"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.data.Dataset.from_tensor_slices((features, labels))将数据与标签配对</span><br><span class="line">tf.GradientTape()实现loss对参数w的求导计算，如图(需要variable类型)</span><br><span class="line">enumerate(列表&#x2F;元组&#x2F;字符串)枚举每一个元素并组合为索引元素(为python自带函数)</span><br><span class="line">tf.one_hot(tf, depth&#x3D;几分类)</span><br><span class="line">tf.nn.softmax(tf)将数据转换为总和为一且每一项大于0的数据，常用于逻辑回归</span><br><span class="line">tf.assign_sub(w自减内容)，赋值操作，更新参数并返回(需要variable类型)</span><br><span class="line">tf.argmax(tf,axis&#x3D;)返回指定轴最大值索引</span><br><span class="line">tf.where(条件语句, a, b)若为真返回a对应位置元素，若为假返回b对应位置元素</span><br><span class="line">np.random.RandomState.rand(维度)</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/12/21/RCuek7PGmlYi9dt.png" alt="image-20201221121900348"></p>
<p>独热码one-hot</p>
<p><img src="https://i.loli.net/2020/12/21/hIBvDdnt72wNL3W.png" alt="image-20201221123854796"></p>
<h3 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">x_data&#x3D;datasets.load_iris().data获取特征值</span><br><span class="line">y_data&#x3D;datasets.load_iris().target获取标签</span><br></pre></td></tr></table></figure>

<h2 id="numpy常用函数"><a href="#numpy常用函数" class="headerlink" title="numpy常用函数"></a>numpy常用函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.random.RandomState.rand(维度)</span><br><span class="line">np.vstack(数组1, 数组2)两个数组垂直方向叠加</span><br></pre></td></tr></table></figure>

<p>随机数种子</p>
<p><img src="https://i.loli.net/2020/12/21/DdpIyYWfaXA5xh1.png" alt="image-20201221153210793"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.mgrid[]		&#125;</span><br><span class="line">np.ravel()		&#125;联合使用可以创建网格坐标点，如下图</span><br><span class="line">np.c_[]			&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/12/21/LyxnkhZBW5zN7JD.png" alt="image-20201221154627787"></p>
<h2 id="神经网络实现"><a href="#神经网络实现" class="headerlink" title="神经网络实现"></a>神经网络实现</h2><h3 id="指数衰减学习率"><a href="#指数衰减学习率" class="headerlink" title="指数衰减学习率"></a>指数衰减学习率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">w = tf.Variable(tf.constant(<span class="number">5</span>, dtype=tf.float32))</span><br><span class="line"></span><br><span class="line">epoch = <span class="number">40</span></span><br><span class="line">LR_BASE = <span class="number">0.2</span>  <span class="comment"># 最初学习率</span></span><br><span class="line">LR_DECAY = <span class="number">0.99</span>  <span class="comment"># 学习率衰减率</span></span><br><span class="line">LR_STEP = <span class="number">1</span>  <span class="comment"># 喂入多少轮BATCH_SIZE后，更新一次学习率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch):  <span class="comment"># for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环100次迭代。</span></span><br><span class="line">    lr = LR_BASE * LR_DECAY ** (epoch / LR_STEP)</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># with结构到grads框起了梯度的计算过程。</span></span><br><span class="line">        loss = tf.square(w + <span class="number">1</span>)</span><br><span class="line">    grads = tape.gradient(loss, w)  <span class="comment"># .gradient函数告知谁对谁求导</span></span><br><span class="line"></span><br><span class="line">    w.assign_sub(lr * grads)  <span class="comment"># .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads</span></span><br><span class="line">    print(<span class="string">&quot;After %s epoch,w is %f,loss is %f,lr is %f&quot;</span> % (epoch, w.numpy(), loss, lr))</span><br></pre></td></tr></table></figure>

<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><h4 id="relu函数"><a href="#relu函数" class="headerlink" title="relu函数"></a>relu函数</h4><p>初学者首选</p>
<p><img src="https://i.loli.net/2020/11/19/6snpNe8GCmvj7I9.png" alt="img"></p>
<p><img src="https://i.loli.net/2020/12/21/ScVf1xabOjqnoXF.png" alt="image-20201221155858186"></p>
<p>均值非0导致收敛变慢，同时可能存在dead_relu问题，即激活函数输出为0，反向传播得到梯度为0，参数无法更新，神经元死亡</p>
<p>改进方法：随机初始化，减小学习率</p>
<h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p><img src="https://i.loli.net/2020/11/19/AbBgPzp32NdOSkW.png" alt="img"></p>
<p><img src="https://i.loli.net/2020/12/21/qxAvKV3mgzO8tbH.png" alt="image-20201221155530105"></p>
<p>反向传播需要多个导数项相乘，sigmoid函数导数都在0~0.25之间，导致梯度消失，参数无法继续更新；同时，存在幂运算导致计算量偏大</p>
<h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><p><img src="https://i.loli.net/2020/11/19/ZrLTUHJi6PFQtB7.png" alt="img"></p>
<p><img src="https://i.loli.net/2020/12/21/pf2iakB6LUATunb.png" alt="image-20201221155725328"></p>
<p>与sigmoid函数相同，具有梯度消失和幂运算问题</p>
<h4 id="leak-relu函数"><a href="#leak-relu函数" class="headerlink" title="leak relu函数"></a>leak relu函数</h4><p>负值影响较小</p>
<p><img src="https://i.loli.net/2020/11/20/VgTpCzkEPYJKGIn.png" alt="img"></p>
<p>效果比relu更好，但一般还是选择relu</p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplot-inline</span><br><span class="line"></span><br><span class="line">data=pd.read_csv(<span class="string">&quot;./datasets.csv&quot;</span>)</span><br><span class="line">x = data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">y = data.iloc[:, <span class="number">-1</span>]</span><br><span class="line"><span class="comment">#建立多层模型</span></span><br><span class="line">model = tf.keras.Sequential([tf.keras.layers.Dense(<span class="number">10</span>, input_shape=(<span class="number">3</span>,), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                            tf.keras.layers.Dense(<span class="number">1</span>)]</span><br><span class="line">)</span><br><span class="line"><span class="comment">#查看模型总体数据</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#模型配置(优化方法adam,损失函数mse均方差)</span></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line"><span class="comment">#训练模型(epochs表示次数)</span></span><br><span class="line">model.fit(x,y,epochs=<span class="number">1000</span>)</span><br><span class="line"><span class="comment">#预测数据</span></span><br><span class="line">model.predict(Test)</span><br></pre></td></tr></table></figure>

<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_mean(tf)计算均方差</span><br><span class="line">tf.losses.categorical_crossentropy(y_, y)计算交叉熵</span><br><span class="line">tf.nn.softmax_cross_entropy_with_logits(y_, y)将softmax与交叉熵结合，用于多分类问题</span><br><span class="line">自定义损失函数，如下图</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/12/21/hixnQZJ365IbyFK.png" alt="image-20201221162135559"></p>
<p><img src="https://i.loli.net/2020/12/21/whT9eGHlLZqRkEC.png" alt="image-20201221162430270"></p>
<h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p><img src="https://i.loli.net/2020/12/21/O8Re3jfX2nC7kQq.png" alt="image-20201221163023605"></p>
<h3 id="神经网络参数优化器"><a href="#神经网络参数优化器" class="headerlink" title="神经网络参数优化器"></a>神经网络参数优化器</h3><p><img src="https://i.loli.net/2020/12/21/3esCl2RQxMFTpNq.png" alt="image-20201221163833148"></p>
<h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><p><img src="https://i.loli.net/2020/12/21/ybqoa5lWQA9vghF.png" alt="image-20201221165530498"></p>
<h4 id="SGDM"><a href="#SGDM" class="headerlink" title="SGDM"></a>SGDM</h4><p><img src="https://i.loli.net/2020/12/21/HBxnvPEhOjg4aRF.png" alt="image-20201221165649601"></p>
<p>m_t-1表示上一时刻的动量</p>
<p>实现代码(部分)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">m_w, m_b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">beta = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">m_w = beta * m_w + (<span class="number">1</span> - beta) * grads[<span class="number">0</span>]</span><br><span class="line">        m_b = beta * m_b + (<span class="number">1</span> - beta) * grads[<span class="number">1</span>]</span><br><span class="line">        w1.assign_sub(lr * m_w)</span><br><span class="line">        b1.assign_sub(lr * m_b)</span><br></pre></td></tr></table></figure>

<h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><p><img src="https://i.loli.net/2020/12/21/tjugIfeDqPkO7sV.png" alt="image-20201221170155720"></p>
<p>实现代码(部分)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">v_w, v_b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">v_w += tf.square(grads[<span class="number">0</span>])</span><br><span class="line">v_b += tf.square(grads[<span class="number">1</span>])</span><br><span class="line">w1.assign_sub(lr * grads[<span class="number">0</span>] / tf.sqrt(v_w))</span><br><span class="line">b1.assign_sub(lr * grads[<span class="number">1</span>] / tf.sqrt(v_b))</span><br></pre></td></tr></table></figure>

<h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><p><img src="https://i.loli.net/2020/12/21/rfJIpYXoU718d4c.png" alt="image-20201221233035802"></p>
<p>代码实现(部分)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">v_w, v_b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">beta = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">v_w = beta * v_w + (<span class="number">1</span> - beta) * tf.square(grads[<span class="number">0</span>])</span><br><span class="line">v_b = beta * v_b + (<span class="number">1</span> - beta) * tf.square(grads[<span class="number">1</span>])</span><br><span class="line">w1.assign_sub(lr * grads[<span class="number">0</span>] / tf.sqrt(v_w))</span><br><span class="line">b1.assign_sub(lr * grads[<span class="number">1</span>] / tf.sqrt(v_b))</span><br></pre></td></tr></table></figure>

<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p><img src="https://i.loli.net/2020/12/21/So4DFhWf3BwrV9A.png" alt="image-20201221233441518"></p>
<p>代码实现(部分)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">m_w, m_b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">v_w, v_b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">beta1, beta2 = <span class="number">0.9</span>, <span class="number">0.999</span></span><br><span class="line">delta_w, delta_b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">global_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">m_w = beta1 * m_w + (<span class="number">1</span> - beta1) * grads[<span class="number">0</span>]</span><br><span class="line">m_b = beta1 * m_b + (<span class="number">1</span> - beta1) * grads[<span class="number">1</span>]</span><br><span class="line">v_w = beta2 * v_w + (<span class="number">1</span> - beta2) * tf.square(grads[<span class="number">0</span>])</span><br><span class="line">v_b = beta2 * v_b + (<span class="number">1</span> - beta2) * tf.square(grads[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">m_w_correction = m_w / (<span class="number">1</span> - tf.pow(beta1, int(global_step)))</span><br><span class="line">m_b_correction = m_b / (<span class="number">1</span> - tf.pow(beta1, int(global_step)))</span><br><span class="line">v_w_correction = v_w / (<span class="number">1</span> - tf.pow(beta2, int(global_step)))</span><br><span class="line">v_b_correction = v_b / (<span class="number">1</span> - tf.pow(beta2, int(global_step)))</span><br><span class="line"></span><br><span class="line">w1.assign_sub(lr * m_w_correction / tf.sqrt(v_w_correction))</span><br><span class="line">b1.assign_sub(lr * m_b_correction / tf.sqrt(v_b_correction))</span><br></pre></td></tr></table></figure>

<h2 id="全连接网络"><a href="#全连接网络" class="headerlink" title="全连接网络"></a>全连接网络</h2><p>六步法搭建神经网络</p>
<ul>
<li>import</li>
<li>train, test</li>
<li>model=tf.keras.models.Sequential</li>
<li>model.compile</li>
<li>model.fit</li>
<li>model.summary</li>
</ul>
<h3 id="方法描述"><a href="#方法描述" class="headerlink" title="方法描述"></a>方法描述</h3><h4 id="model-tf-keras-models-Sequential"><a href="#model-tf-keras-models-Sequential" class="headerlink" title="model=tf.keras.models.Sequential"></a>model=tf.keras.models.Sequential</h4><p>包含了各种网络结构：拉直层、全连接层、卷积层、LSTM层</p>
<p><img src="https://i.loli.net/2020/12/21/fpkcAGlVC2FIz8Z.png" alt="image-20201221234451260"></p>
<h5 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h5><p><img src="https://i.loli.net/2020/12/21/qAmVlzCeFUaQodg.png" alt="image-20201221234815182"></p>
<h5 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h5><p>使用时validation_data和validation_split二选一</p>
<p><img src="https://i.loli.net/2020/12/21/H2JcEDCTWRgGMkP.png" alt="image-20201221234952677"></p>
<h5 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h5><p>在终端输出训练结果</p>
<h5 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line"><span class="comment">#打乱数据集，使用相同的seed保证输入特征和标签对应</span></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h4 id="class-MyModel-Model-model-MyModel"><a href="#class-MyModel-Model-model-MyModel" class="headerlink" title="class MyModel(Model) model=MyModel"></a>class MyModel(Model) model=MyModel</h4><p>将之前的Sequential替换为自定义class继承Model类</p>
<p><img src="https://i.loli.net/2020/12/22/dhiJTE7Y61LbGMU.png" alt="image-20201222142747894"></p>
<h5 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h5><p>相比之下，导入模块增加了<code>Dense</code>和<code>Model</code>，然后自定义<code>IrisModel</code>类来创建神经网络结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IrisModel</span>(<span class="params">Model</span>):</span><span class="comment">#自定义类</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(IrisModel, self).__init__()</span><br><span class="line">        self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        y = self.d1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = IrisModel()</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h4 id="mnist数据集"><a href="#mnist数据集" class="headerlink" title="mnist数据集"></a>mnist数据集</h4><p><img src="https://i.loli.net/2020/12/22/6xrMUNYS4Pgdbhf.png" alt="image-20201222143513639"></p>
<h5 id="查看数据集"><a href="#查看数据集" class="headerlink" title="查看数据集"></a>查看数据集</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化训练集输入特征的第一个元素</span></span><br><span class="line">plt.imshow(x_train[<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 绘制灰度图</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印出训练集输入特征的第一个元素</span></span><br><span class="line">print(<span class="string">&quot;x_train[0]:\n&quot;</span>, x_train[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 打印出训练集标签的第一个元素</span></span><br><span class="line">print(<span class="string">&quot;y_train[0]:\n&quot;</span>, y_train[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印出整个训练集输入特征形状</span></span><br><span class="line">print(<span class="string">&quot;x_train.shape:\n&quot;</span>, x_train.shape)</span><br><span class="line"><span class="comment"># 打印出整个训练集标签的形状</span></span><br><span class="line">print(<span class="string">&quot;y_train.shape:\n&quot;</span>, y_train.shape)</span><br><span class="line"><span class="comment"># 打印出整个测试集输入特征的形状</span></span><br><span class="line">print(<span class="string">&quot;x_test.shape:\n&quot;</span>, x_test.shape)</span><br><span class="line"><span class="comment"># 打印出整个测试集标签的形状</span></span><br><span class="line">print(<span class="string">&quot;y_test.shape:\n&quot;</span>, y_test.shape)</span><br></pre></td></tr></table></figure>

<h5 id="Sequential实现"><a href="#Sequential实现" class="headerlink" title="Sequential实现"></a>Sequential实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="自定义class实现"><a href="#自定义class实现" class="headerlink" title="自定义class实现"></a>自定义class实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MnistModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(MnistModel, self).__init__()</span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        y = self.d2(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MnistModel()</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h4 id="fashion数据集"><a href="#fashion数据集" class="headerlink" title="fashion数据集"></a>fashion数据集</h4><p><img src="https://i.loli.net/2020/12/22/wkdYRCqVHcMOuxA.png" alt="image-20201222151008787"></p>
<h5 id="Sequential实现-1"><a href="#Sequential实现-1" class="headerlink" title="Sequential实现"></a>Sequential实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">fashion = tf.keras.datasets.fashion_mnist</span><br><span class="line">(x_train, y_train),(x_test, y_test) = fashion.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h3 id="补充方法"><a href="#补充方法" class="headerlink" title="补充方法"></a>补充方法</h3><h4 id="自制数据集"><a href="#自制数据集" class="headerlink" title="自制数据集"></a>自制数据集</h4><h5 id="实现代码-部分"><a href="#实现代码-部分" class="headerlink" title="实现代码(部分)"></a>实现代码(部分)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">train_path = <span class="string">&#x27;./mnist_image_label/mnist_train_jpg_60000/&#x27;</span></span><br><span class="line">train_txt = <span class="string">&#x27;./mnist_image_label/mnist_train_jpg_60000.txt&#x27;</span></span><br><span class="line">x_train_savepath = <span class="string">&#x27;./mnist_image_label/mnist_x_train.npy&#x27;</span></span><br><span class="line">y_train_savepath = <span class="string">&#x27;./mnist_image_label/mnist_y_train.npy&#x27;</span></span><br><span class="line"></span><br><span class="line">test_path = <span class="string">&#x27;./mnist_image_label/mnist_test_jpg_10000/&#x27;</span></span><br><span class="line">test_txt = <span class="string">&#x27;./mnist_image_label/mnist_test_jpg_10000.txt&#x27;</span></span><br><span class="line">x_test_savepath = <span class="string">&#x27;./mnist_image_label/mnist_x_test.npy&#x27;</span></span><br><span class="line">y_test_savepath = <span class="string">&#x27;./mnist_image_label/mnist_y_test.npy&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateds</span>(<span class="params">path, txt</span>):</span></span><br><span class="line">    f = open(txt, <span class="string">&#x27;r&#x27;</span>)  <span class="comment"># 以只读形式打开txt文件</span></span><br><span class="line">    contents = f.readlines()  <span class="comment"># 读取文件中所有行</span></span><br><span class="line">    f.close()  <span class="comment"># 关闭txt文件</span></span><br><span class="line">    x, y_ = [], []  <span class="comment"># 建立空列表</span></span><br><span class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> contents:  <span class="comment"># 逐行取出</span></span><br><span class="line">        value = content.split()  <span class="comment"># 以空格分开，图片路径为value[0] , 标签为value[1] , 存入列表</span></span><br><span class="line">        img_path = path + value[<span class="number">0</span>]  <span class="comment"># 拼出图片路径和文件名</span></span><br><span class="line">        img = Image.open(img_path)  <span class="comment"># 读入图片</span></span><br><span class="line">        img = np.array(img.convert(<span class="string">&#x27;L&#x27;</span>))  <span class="comment"># 图片变为8位宽灰度值的np.array格式</span></span><br><span class="line">        img = img / <span class="number">255.</span>  <span class="comment"># 数据归一化 （实现预处理）</span></span><br><span class="line">        x.append(img)  <span class="comment"># 归一化后的数据，贴到列表x</span></span><br><span class="line">        y_.append(value[<span class="number">1</span>])  <span class="comment"># 标签贴到列表y_</span></span><br><span class="line">        print(<span class="string">&#x27;loading : &#x27;</span> + content)  <span class="comment"># 打印状态提示</span></span><br><span class="line"></span><br><span class="line">    x = np.array(x)  <span class="comment"># 变为np.array格式</span></span><br><span class="line">    y_ = np.array(y_)  <span class="comment"># 变为np.array格式</span></span><br><span class="line">    y_ = y_.astype(np.int64)  <span class="comment"># 变为64位整型</span></span><br><span class="line">    <span class="keyword">return</span> x, y_  <span class="comment"># 返回输入特征x，返回标签y_</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(x_train_savepath) <span class="keyword">and</span> os.path.exists(y_train_savepath) <span class="keyword">and</span> os.path.exists(</span><br><span class="line">        x_test_savepath) <span class="keyword">and</span> os.path.exists(y_test_savepath):</span><br><span class="line">    print(<span class="string">&#x27;-------------Load Datasets-----------------&#x27;</span>)</span><br><span class="line">    x_train_save = np.load(x_train_savepath)</span><br><span class="line">    y_train = np.load(y_train_savepath)</span><br><span class="line">    x_test_save = np.load(x_test_savepath)</span><br><span class="line">    y_test = np.load(y_test_savepath)</span><br><span class="line">    x_train = np.reshape(x_train_save, (len(x_train_save), <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    x_test = np.reshape(x_test_save, (len(x_test_save), <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">&#x27;-------------Generate Datasets-----------------&#x27;</span>)</span><br><span class="line">    x_train, y_train = generateds(train_path, train_txt)</span><br><span class="line">    x_test, y_test = generateds(test_path, test_txt)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;-------------Save Datasets-----------------&#x27;</span>)</span><br><span class="line">    x_train_save = np.reshape(x_train, (len(x_train), <span class="number">-1</span>))</span><br><span class="line">    x_test_save = np.reshape(x_test, (len(x_test), <span class="number">-1</span>))</span><br><span class="line">    np.save(x_train_savepath, x_train_save)</span><br><span class="line">    np.save(y_train_savepath, y_train)</span><br><span class="line">    np.save(x_test_savepath, x_test_save)</span><br><span class="line">    np.save(y_test_savepath, y_test)</span><br></pre></td></tr></table></figure>

<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>可用作增大数据量</p>
<p><img src="https://i.loli.net/2020/12/22/mKfH5dh6pvRkBMq.png" alt="image-20201222160932779"></p>
<h5 id="fit-1"><a href="#fit-1" class="headerlink" title="fit"></a>fit</h5><p><code>fit(x, augment=False, rounds=1, seed=None)</code></p>
<p>将数据生成器用于某些样本数据数据。它基于一组样本数据，计算与数据转换相关的内部数据统计。当且仅当 <code>featurewise_center</code> 或 <code>featurewise_std_normalization</code> 或 <code>zca_whitening</code> 设置为 True 时才需要。</p>
<ul>
<li><strong>x</strong>: 样本数据。秩应该为 4，即（batch，width，height，channel）的格式。对于灰度数据，通道轴的值应该为 1；对于 RGB 数据，值应该为 3。</li>
<li><strong>augment</strong>: 布尔值（默认为 False）。是否使用随机样本扩张。</li>
<li><strong>rounds</strong>: 整数（默认为 1）。如果数据数据增强（augment=True），表明在数据上进行多少次增强。</li>
<li><strong>seed</strong>: 整数（默认 None）。随机种子。</li>
</ul>
<h5 id="flow"><a href="#flow" class="headerlink" title="flow"></a>flow</h5><p><code>flow(x, y=None, batch_size=32, shuffle=True, sample_weight=None, seed=None, save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;png&#39;, subset=None)</code></p>
<p>采集数据和标签数组，生成批量增强数据。</p>
<ul>
<li><strong>x</strong>: 输入数据。秩为 4 的 Numpy 矩阵或元组。如果是元组，第一个元素应该包含图像，第二个元素是另一个 Numpy 数组或一列 Numpy 数组，它们不经过任何修改就传递给输出。可用于将模型杂项数据与图像一起输入。对于灰度数据，图像数组的通道轴的值应该为 1，而对于 RGB 数据，其值应该为 3。</li>
<li><strong>y</strong>: 标签。</li>
<li><strong>batch_size</strong>: 整数 (默认为 32)。</li>
<li><strong>shuffle</strong>: 布尔值 (默认为 True)。</li>
<li><strong>sample_weight</strong>: 样本权重。</li>
<li><strong>seed</strong>: 整数（默认为 None）。</li>
<li><strong>save_to_dir</strong>: None 或 字符串（默认为 None）。这使您可以选择指定要保存的正在生成的增强图片的目录（用于可视化您正在执行的操作）。</li>
<li><strong>save_prefix</strong>: 字符串（默认 <code>&#39;&#39;</code>）。保存图片的文件名前缀（仅当 <code>save_to_dir</code> 设置时可用）。</li>
<li><strong>save_format</strong>: “png”, “jpeg” 之一（仅当 <code>save_to_dir</code> 设置时可用）。默认：”png”。</li>
<li><strong>subset</strong>: 数据子集 (“training” 或 “validation”)，如果 在 <code>ImageDataGenerator</code> 中设置了 <code>validation_split</code>。</li>
</ul>
<p>返回一个生成元组 <code>(x, y)</code> 的 生成器<code>Iterator</code>，其中 <code>x</code> 是图像数据的 Numpy 数组（在单张图像输入时），或 Numpy 数组列表（在额外多个输入时），<code>y</code> 是对应的标签的 Numpy 数组。如果 ‘sample_weight’ 不是 None，生成的元组形式为 <code>(x, y, sample_weight)</code>。如果 <code>y</code> 是 None, 只有 Numpy 数组 <code>x</code> 被返回。</p>
<h5 id="实现代码-部分-1"><a href="#实现代码-部分-1" class="headerlink" title="实现代码(部分)"></a>实现代码(部分)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)<span class="comment">#fit要求秩为4</span></span><br><span class="line">image_gen_train = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span> / <span class="number">1.</span>,  <span class="comment"># 如为图像，分母为255时，可归至0～1</span></span><br><span class="line">    rotation_range=<span class="number">45</span>,  <span class="comment"># 随机45度旋转</span></span><br><span class="line">    width_shift_range=<span class="number">.15</span>,  <span class="comment"># 宽度偏移</span></span><br><span class="line">    height_shift_range=<span class="number">.15</span>,  <span class="comment"># 高度偏移</span></span><br><span class="line">    horizontal_flip=<span class="literal">False</span>,  <span class="comment"># 水平翻转</span></span><br><span class="line">    zoom_range=<span class="number">0.5</span>  <span class="comment"># 将图像随机缩放阈量50％</span></span><br><span class="line">)</span><br><span class="line">image_gen_train.fit(x_train)</span><br><span class="line"></span><br><span class="line">model.fit(image_gen_train.flow(x_train, y_train, batch_size=<span class="number">32</span>), epochs=<span class="number">5</span>, validation_data=(x_test, y_test),</span><br><span class="line">          validation_freq=<span class="number">1</span>)<span class="comment">#填入训练数据和标签要用flow函数生成增强数据</span></span><br></pre></td></tr></table></figure>

<h4 id="断点续训"><a href="#断点续训" class="headerlink" title="断点续训"></a>断点续训</h4><p>将之前训练好的模型加载进来，在原来模型的基础上再进行训练</p>
<p><img src="https://cdn.jsdelivr.net/gh/lan5th/pics/blog_images/image-20201223095033595.png" alt="image-20201223095033595"></p>
<h5 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/mnist.ckpt&quot;</span><span class="comment">#保存模型路径</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):<span class="comment">#检查是否已生成索引表</span></span><br><span class="line">    print(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)<span class="comment">#加载模型</span></span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)<span class="comment">#回调函数</span></span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])<span class="comment">#添加callback选项，若没有checkpoint文件夹则会自动创建</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h4 id="参数提取"><a href="#参数提取" class="headerlink" title="参数提取"></a>参数提取</h4><p><img src="https://i.loli.net/2020/12/23/jh5svyZizwU4Rx2.png" alt="image-20201223101139650"></p>
<h5 id="实现代码-部分-2"><a href="#实现代码-部分-2" class="headerlink" title="实现代码(部分)"></a>实现代码(部分)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">print(model.trainable_variables)</span><br><span class="line">file = open(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(str(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(str(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(str(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure>

<h4 id="acc-loss可视化"><a href="#acc-loss可视化" class="headerlink" title="acc/loss可视化"></a>acc/loss可视化</h4><p>加入绘图模块</p>
<p>实现代码(部分)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])<span class="comment">#将模型传给history</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="实现预测"><a href="#实现预测" class="headerlink" title="实现预测"></a>实现预测</h4><p>在已训练好模型的基础上实现预测</p>
<p><img src="https://i.loli.net/2020/12/23/ImxZkehCEloinvP.png" alt="image-20201223103609620"></p>
<h5 id="实现代码-部分-3"><a href="#实现代码-部分-3" class="headerlink" title="实现代码(部分)"></a>实现代码(部分)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(preNum):</span><br><span class="line">    image_path = input(<span class="string">&quot;the path of test picture:&quot;</span>)</span><br><span class="line">    img = Image.open(image_path)</span><br><span class="line">    img = img.resize((<span class="number">28</span>, <span class="number">28</span>), Image.ANTIALIAS)</span><br><span class="line">    img_arr = np.array(img.convert(<span class="string">&#x27;L&#x27;</span>))<span class="comment">#转换为灰度值表示</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">28</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">28</span>):</span><br><span class="line">            <span class="keyword">if</span> img_arr[i][j] &lt; <span class="number">200</span>:<span class="comment">#噪声过滤</span></span><br><span class="line">                img_arr[i][j] = <span class="number">255</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                img_arr[i][j] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    img_arr = img_arr / <span class="number">255.0</span><span class="comment">#归一化</span></span><br><span class="line">    x_predict = img_arr[tf.newaxis, ...]<span class="comment">#增加维度</span></span><br><span class="line">    result = model.predict(x_predict)<span class="comment">#进行预测</span></span><br><span class="line">    pred = tf.argmax(result, axis=<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    tf.print(pred)</span><br></pre></td></tr></table></figure>

<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><h4 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h4><p>输出层对应特征为此时对应位置所有特征乘积之和</p>
<p><img src="https://i.loli.net/2020/12/23/FiPRgWhA7ubK2EV.png" alt="image-20201223105856460"></p>
<p>单通道卷积核</p>
<img src="https://i.loli.net/2020/12/23/vqFpwWurBDbJXmf.png" alt="image-20201223110035869"  />

<p>三通道卷积核</p>
<img src="https://i.loli.net/2020/12/23/wvumgzbaKsHAhpy.png" alt="image-20201223110035869" style="zoom:200%;" />

<h4 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h4><p>如图，黄色的卷积核感受野为3×3，绿色和蓝色卷积核的感受野为5×5</p>
<p><img src="https://i.loli.net/2020/12/23/VytBqKxFHUmDpEX.png" alt="image-20201223111247005"></p>
<h4 id="全零填充"><a href="#全零填充" class="headerlink" title="全零填充"></a>全零填充</h4><p>在输入图的周围填充一层0</p>
<p><img src="https://i.loli.net/2020/12/23/q4PLidCgnhoWKtT.png" alt="image-20201223111516974"></p>
<h4 id="实现卷积层"><a href="#实现卷积层" class="headerlink" title="实现卷积层"></a>实现卷积层</h4><p><img src="https://i.loli.net/2020/12/23/tgZc7Av5HXTGfyw.png" alt="image-20201223112144294"></p>
<h4 id="批标准化BN"><a href="#批标准化BN" class="headerlink" title="批标准化BN"></a>批标准化BN</h4><p>位于卷积层之后，激活层之前</p>
<p><img src="https://i.loli.net/2020/12/23/EaBp62TIdDwPRYo.png" alt="image-20201223112637606"></p>
<p>归一化提升了激活函数对输入数据的区分力，但会使得函数丧失非线性，可添加参数作以调整</p>
<p><img src="https://i.loli.net/2020/12/23/YZOxBVvSa16U9Io.png" alt="image-20201223112926668"></p>
<p>tf实现</p>
<p><img src="https://i.loli.net/2020/12/23/lP1OcHYXnIqwJa5.png" alt="image-20201223113837324"></p>
<h4 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h4><p>减少卷积神经网络中特征数据量</p>
<p>最大池化提取图片纹理</p>
<p>均值池化保留背景特征</p>
<p>如图使用2×2的池化核对4×4图片进行操作，每次移动步长为2，得到不同的结果</p>
<p><img src="https://i.loli.net/2020/12/23/jrHPGopIh7u31ls.png" alt="image-20201223161305084"></p>
<p><img src="https://i.loli.net/2020/12/23/velEPCKORxoDa4t.png" alt="image-20201223161546439"></p>
<h4 id="舍弃"><a href="#舍弃" class="headerlink" title="舍弃"></a>舍弃</h4><p>训练时随机舍弃一部分神经元，防止过拟合，使用时回复神经元</p>
<p><img src="https://i.loli.net/2020/12/23/8wpHBLQCaIGrMWP.png" alt="image-20201223161704792"></p>
<h3 id="总体实现"><a href="#总体实现" class="headerlink" title="总体实现"></a>总体实现</h3><p>过程：CBAPD</p>
<ul>
<li>卷积核()</li>
<li>批标准化()</li>
<li>激活函数()</li>
<li>池化核()</li>
<li>舍弃()</li>
</ul>
<p><img src="https://i.loli.net/2020/12/23/yt1NViczEWI8lOh.png" alt="image-20201223162600423"></p>
<h4 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h4><p>之后的经典卷积网络都基于此代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Baseline</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(Baseline, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), padding=<span class="string">&#x27;same&#x27;</span>)  <span class="comment"># 卷积层</span></span><br><span class="line">        self.b1 = BatchNormalization()  <span class="comment"># BN层</span></span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层</span></span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)  <span class="comment"># 池化层</span></span><br><span class="line">        self.d1 = Dropout(<span class="number">0.2</span>)  <span class="comment"># dropout层</span></span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.d2(x)</span><br><span class="line">        y = self.f2(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<h3 id="经典卷积网络"><a href="#经典卷积网络" class="headerlink" title="经典卷积网络"></a>经典卷积网络</h3><p><img src="https://i.loli.net/2020/12/23/b3cpo8GSkNghlaD.png" alt="image-20201223192744044"></p>
<h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><p>共享卷积层减少网络的参数</p>
<p>(统计层数时只统计卷积计算层和全连接计算层)</p>
<p>共5层，2层卷积层，3层全连接层，一层Flatten层</p>
<p><img src="https://i.loli.net/2020/12/23/5q1iUBLj6TxAcvK.png" alt="image-20201223165152017"></p>
<h5 id="模型代码"><a href="#模型代码" class="headerlink" title="模型代码"></a>模型代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet5</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(LeNet5, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                         activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                         activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">120</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">84</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p>共8层，5层卷积层，3层全连接层，一层Flatten层</p>
<p><img src="https://i.loli.net/2020/12/23/i5VR2LlcdC6vmJG.png" alt="image-20201223165825915"></p>
<p>注：LRN近年来使用较少，效果与BN类似，故使用BN作为替代</p>
<h5 id="模型代码-1"><a href="#模型代码-1" class="headerlink" title="模型代码"></a>模型代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet8</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(AlexNet8, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                         </span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                         </span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p>使用小尺寸卷积核，减少参数的同时提高了识别准确率，网络结构规整，适合硬件加速</p>
<p>在CBAPD的卷积层之间加入CBA的卷积层</p>
<h5 id="16层VGGNet实例"><a href="#16层VGGNet实例" class="headerlink" title="16层VGGNet实例"></a>16层VGGNet实例</h5><p><img src="https://i.loli.net/2020/12/23/XQNSZ9jyhtPkIHr.png" alt="image-20201223171207115"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG16</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super(VGG16, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)  <span class="comment"># 卷积层1</span></span><br><span class="line">        self.b1 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>, )</span><br><span class="line">        self.b2 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.2</span>)  <span class="comment"># dropout层</span></span><br><span class="line"></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b3 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a3 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b4 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a4 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.2</span>)  <span class="comment"># dropout层</span></span><br><span class="line"></span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b5 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a5 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c6 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b6 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a6 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c7 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b7 = BatchNormalization()</span><br><span class="line">        self.a7 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d3 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        self.c8 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b8 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a8 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c9 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b9 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a9 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c10 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b10 = BatchNormalization()</span><br><span class="line">        self.a10 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p4 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d4 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        self.c11 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b11 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a11 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c12 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b12 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a12 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c13 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b13 = BatchNormalization()</span><br><span class="line">        self.a13 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p5 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d5 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d6 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d7 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="InceptionNet"><a href="#InceptionNet" class="headerlink" title="InceptionNet"></a>InceptionNet</h4><p>同一层网络中使用不同尺寸的卷积核，提升模型感知力</p>
<p><img src="https://i.loli.net/2020/12/23/LHRhbPFYeCrzmT7.png" alt="image-20201223172019888"></p>
<h5 id="精简版模型代码"><a href="#精简版模型代码" class="headerlink" title="精简版模型代码"></a>精简版模型代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvBNRelu</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, ch, kernelsz=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span></span>):</span></span><br><span class="line">        super(ConvBNRelu, self).__init__()</span><br><span class="line">        self.model = tf.keras.models.Sequential([</span><br><span class="line">            Conv2D(ch, kernelsz, strides=strides, padding=padding),</span><br><span class="line">            BatchNormalization(),</span><br><span class="line">            Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.model(x, training=<span class="literal">False</span>) <span class="comment">#在training=False时，BN通过整个训练集计算均值、方差去做批归一化，training=True时，通过当前batch的均值、方差去做批归一化。推理时 training=False效果好</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionBlk</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, ch, strides=<span class="number">1</span></span>):</span></span><br><span class="line">        super(InceptionBlk, self).__init__()</span><br><span class="line">        self.ch = ch</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.c1 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.c2_1 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.c2_2 = ConvBNRelu(ch, kernelsz=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line">        self.c3_1 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.c3_2 = ConvBNRelu(ch, kernelsz=<span class="number">5</span>, strides=<span class="number">1</span>)</span><br><span class="line">        self.p4_1 = MaxPool2D(<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.c4_2 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.c1(x)</span><br><span class="line">        x2_1 = self.c2_1(x)</span><br><span class="line">        x2_2 = self.c2_2(x2_1)</span><br><span class="line">        x3_1 = self.c3_1(x)</span><br><span class="line">        x3_2 = self.c3_2(x3_1)</span><br><span class="line">        x4_1 = self.p4_1(x)</span><br><span class="line">        x4_2 = self.c4_2(x4_1)</span><br><span class="line">        <span class="comment"># concat along axis=channel</span></span><br><span class="line">        x = tf.concat([x1, x2_2, x3_2, x4_2], axis=<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception10</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_blocks, num_classes, init_ch=<span class="number">16</span>, **kwargs</span>):</span></span><br><span class="line">        super(Inception10, self).__init__(**kwargs)</span><br><span class="line">        self.in_channels = init_ch</span><br><span class="line">        self.out_channels = init_ch</span><br><span class="line">        self.num_blocks = num_blocks</span><br><span class="line">        self.init_ch = init_ch</span><br><span class="line">        self.c1 = ConvBNRelu(init_ch)</span><br><span class="line">        self.blocks = tf.keras.models.Sequential()</span><br><span class="line">        <span class="keyword">for</span> block_id <span class="keyword">in</span> range(num_blocks):</span><br><span class="line">            <span class="keyword">for</span> layer_id <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">                <span class="keyword">if</span> layer_id == <span class="number">0</span>:</span><br><span class="line">                    block = InceptionBlk(self.out_channels, strides=<span class="number">2</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    block = InceptionBlk(self.out_channels, strides=<span class="number">1</span>)</span><br><span class="line">                self.blocks.add(block)</span><br><span class="line">            <span class="comment"># enlarger out_channels per block</span></span><br><span class="line">            self.out_channels *= <span class="number">2</span></span><br><span class="line">        self.p1 = GlobalAveragePooling2D()</span><br><span class="line">        self.f1 = Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.blocks(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        y = self.f1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>

<h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>应用层间残差跳连，缓解梯度消失</p>
<p><img src="https://i.loli.net/2020/12/23/FEgqiMYczfCX4Wy.png" alt="image-20201223191538804"></p>
<p><img src="https://i.loli.net/2020/12/23/fdwJ2xPZGXRmehB.png" alt="image-20201223192328864"></p>
<h5 id="模型代码-2"><a href="#模型代码-2" class="headerlink" title="模型代码"></a>模型代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResnetBlock</span>(<span class="params">Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filters, strides=<span class="number">1</span>, residual_path=False</span>):</span></span><br><span class="line">        super(ResnetBlock, self).__init__()</span><br><span class="line">        self.filters = filters</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.residual_path = residual_path</span><br><span class="line"></span><br><span class="line">        self.c1 = Conv2D(filters, (<span class="number">3</span>, <span class="number">3</span>), strides=strides, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># residual_path为True时，对输入进行下采样，即用1x1的卷积核做卷积操作，保证x能和F(x)维度相同，顺利相加</span></span><br><span class="line">        <span class="keyword">if</span> residual_path:</span><br><span class="line">            self.down_c1 = Conv2D(filters, (<span class="number">1</span>, <span class="number">1</span>), strides=strides, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">            self.down_b1 = BatchNormalization()</span><br><span class="line">        </span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>实现短期记忆</p>
<h3 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h3><h4 id="循环核"><a href="#循环核" class="headerlink" title="循环核"></a>循环核</h4><p>具有’记忆力‘，通过不同时刻的参数共享实现对时间序列的信息提取</p>
<p><img src="https://i.loli.net/2020/12/23/Qm6tfnDTAlvaWyr.png" alt="image-20201223194307322"></p>
<p><img src="https://pic1.zhimg.com/80/v2-206db7ba9d32a80ff56b6cc988a62440_720w.jpg" alt="image"></p>
<h6 id="循环核时间步展开"><a href="#循环核时间步展开" class="headerlink" title="循环核时间步展开"></a>循环核时间步展开</h6><p><img src="https://pic2.zhimg.com/80/v2-b0175ebd3419f9a11a3d0d8b00e28675_720w.jpg"></p>
<p><img src="https://i.loli.net/2020/12/23/Znw1AJ2cg3XTsjb.png" alt="image-20201223194743291"></p>
<h6 id="循环计算层"><a href="#循环计算层" class="headerlink" title="循环计算层"></a>循环计算层</h6><p>越靠近输出方向层数越高</p>
<p><img src="https://i.loli.net/2020/12/23/oPOfDW2NdQBzxMm.png" alt="image-20201223195033675"></p>
<h4 id="实现循环计算层"><a href="#实现循环计算层" class="headerlink" title="实现循环计算层"></a>实现循环计算层</h4><p><img src="https://i.loli.net/2020/12/23/d3lPqfMxOe8Wchi.png" alt="image-20201223195742059"></p>
<p><img src="https://i.loli.net/2020/12/23/zAJreZmMOqx7cy1.png" alt="image-20201223195725027"></p>
<h4 id="循环计算过程"><a href="#循环计算过程" class="headerlink" title="循环计算过程"></a>循环计算过程</h4><p><img src="https://i.loli.net/2020/12/23/MPFSDNvqnETO3bh.png" alt="image-20201223200745927"></p>
<h3 id="one-hot实现预测字母"><a href="#one-hot实现预测字母" class="headerlink" title="one-hot实现预测字母"></a>one-hot实现预测字母</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, SimpleRNN</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">input_word = <span class="string">&quot;abcde&quot;</span></span><br><span class="line">w_to_id = &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;d&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;e&#x27;</span>: <span class="number">4</span>&#125;  <span class="comment"># 单词映射到数值id的词典</span></span><br><span class="line">id_to_onehot = &#123;<span class="number">0</span>: [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], <span class="number">1</span>: [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], <span class="number">2</span>: [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>], <span class="number">3</span>: [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">                <span class="number">4</span>: [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>]&#125;  <span class="comment"># id编码为one-hot</span></span><br><span class="line"></span><br><span class="line">x_train = [id_to_onehot[w_to_id[<span class="string">&#x27;a&#x27;</span>]], id_to_onehot[w_to_id[<span class="string">&#x27;b&#x27;</span>]], id_to_onehot[w_to_id[<span class="string">&#x27;c&#x27;</span>]],</span><br><span class="line">           id_to_onehot[w_to_id[<span class="string">&#x27;d&#x27;</span>]], id_to_onehot[w_to_id[<span class="string">&#x27;e&#x27;</span>]]]</span><br><span class="line">y_train = [w_to_id[<span class="string">&#x27;b&#x27;</span>], w_to_id[<span class="string">&#x27;c&#x27;</span>], w_to_id[<span class="string">&#x27;d&#x27;</span>], w_to_id[<span class="string">&#x27;e&#x27;</span>], w_to_id[<span class="string">&#x27;a&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">7</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">7</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使x_train符合SimpleRNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。</span></span><br><span class="line"><span class="comment"># 此处整个数据集送入，送入样本数为len(x_train)；输入1个字母出结果，循环核时间展开步数为1; 表示为独热码有5个输入特征，每个时间步输入特征个数为5</span></span><br><span class="line">x_train = np.reshape(x_train, (len(x_train), <span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">y_train = np.array(y_train)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    SimpleRNN(<span class="number">3</span>),</span><br><span class="line">    Dense(<span class="number">5</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/rnn_onehot_1pre1.ckpt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    print(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>,</span><br><span class="line">                                                 monitor=<span class="string">&#x27;loss&#x27;</span>)  <span class="comment"># 由于fit没有给出测试集，不计算测试集准确率，根据loss，保存最优模型</span></span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">100</span>, callbacks=[cp_callback])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = open(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)  <span class="comment"># 参数提取</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(str(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(str(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(str(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">############### predict #############</span></span><br><span class="line"></span><br><span class="line">preNum = int(input(<span class="string">&quot;input the number of test alphabet:&quot;</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(preNum):</span><br><span class="line">    alphabet1 = input(<span class="string">&quot;input test alphabet:&quot;</span>)</span><br><span class="line">    alphabet = [id_to_onehot[w_to_id[alphabet1]]]</span><br><span class="line">    <span class="comment"># 使alphabet符合SimpleRNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。此处验证效果送入了1个样本，送入样本数为1；输入1个字母出结果，所以循环核时间展开步数为1; 表示为独热码有5个输入特征，每个时间步输入特征个数为5</span></span><br><span class="line">    alphabet = np.reshape(alphabet, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">    result = model.predict([alphabet])</span><br><span class="line">    pred = tf.argmax(result, axis=<span class="number">1</span>)</span><br><span class="line">    pred = int(pred)</span><br><span class="line">    tf.print(alphabet1 + <span class="string">&#x27;-&gt;&#x27;</span> + input_word[pred])</span><br></pre></td></tr></table></figure>

<h3 id="Embedding实现预测字母"><a href="#Embedding实现预测字母" class="headerlink" title="Embedding实现预测字母"></a>Embedding实现预测字母</h3><p>用低维向量实现编码</p>
<p><img src="https://i.loli.net/2020/12/23/spUmoR86BkyFIQ1.png" alt="image-20201223204355797"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, SimpleRNN, Embedding</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">input_word = <span class="string">&quot;abcde&quot;</span></span><br><span class="line">w_to_id = &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;d&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;e&#x27;</span>: <span class="number">4</span>&#125;  <span class="comment"># 单词映射到数值id的词典</span></span><br><span class="line"></span><br><span class="line">x_train = [w_to_id[<span class="string">&#x27;a&#x27;</span>], w_to_id[<span class="string">&#x27;b&#x27;</span>], w_to_id[<span class="string">&#x27;c&#x27;</span>], w_to_id[<span class="string">&#x27;d&#x27;</span>], w_to_id[<span class="string">&#x27;e&#x27;</span>]]</span><br><span class="line">y_train = [w_to_id[<span class="string">&#x27;b&#x27;</span>], w_to_id[<span class="string">&#x27;c&#x27;</span>], w_to_id[<span class="string">&#x27;d&#x27;</span>], w_to_id[<span class="string">&#x27;e&#x27;</span>], w_to_id[<span class="string">&#x27;a&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">7</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">7</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使x_train符合Embedding输入要求：[送入样本数， 循环核时间展开步数] ，</span></span><br><span class="line"><span class="comment"># 此处整个数据集送入所以送入，送入样本数为len(x_train)；输入1个字母出结果，循环核时间展开步数为1。</span></span><br><span class="line">x_train = np.reshape(x_train, (len(x_train), <span class="number">1</span>))</span><br><span class="line">y_train = np.array(y_train)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    Embedding(<span class="number">5</span>, <span class="number">2</span>),</span><br><span class="line">    SimpleRNN(<span class="number">3</span>),</span><br><span class="line">    Dense(<span class="number">5</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/run_embedding_1pre1.ckpt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    print(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>,</span><br><span class="line">                                                 monitor=<span class="string">&#x27;loss&#x27;</span>)  <span class="comment"># 由于fit没有给出测试集，不计算测试集准确率，根据loss，保存最优模型</span></span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">100</span>, callbacks=[cp_callback])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = open(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)  <span class="comment"># 参数提取</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(str(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(str(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(str(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">############### predict #############</span></span><br><span class="line"></span><br><span class="line">preNum = int(input(<span class="string">&quot;input the number of test alphabet:&quot;</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(preNum):</span><br><span class="line">    alphabet1 = input(<span class="string">&quot;input test alphabet:&quot;</span>)</span><br><span class="line">    alphabet = [w_to_id[alphabet1]]</span><br><span class="line">    <span class="comment"># 使alphabet符合Embedding输入要求：[送入样本数， 循环核时间展开步数]。</span></span><br><span class="line">    <span class="comment"># 此处验证效果送入了1个样本，送入样本数为1；输入1个字母出结果，循环核时间展开步数为1。</span></span><br><span class="line">    alphabet = np.reshape(alphabet, (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    result = model.predict(alphabet)</span><br><span class="line">    pred = tf.argmax(result, axis=<span class="number">1</span>)</span><br><span class="line">    pred = int(pred)</span><br><span class="line">    tf.print(alphabet1 + <span class="string">&#x27;-&gt;&#x27;</span> + input_word[pred])</span><br></pre></td></tr></table></figure>

<h3 id="长短记忆网络-LSTM"><a href="#长短记忆网络-LSTM" class="headerlink" title="长短记忆网络(LSTM)"></a>长短记忆网络(LSTM)</h3><p><img src="https://i.loli.net/2020/12/23/ajo3ZFGWKPwzvB9.png" alt="image-20201223211401051"></p>
<p>实现方法</p>
<p><img src="https://i.loli.net/2020/12/23/bfMZFEv41rGxOeY.png" alt="image-20201223211512811"></p>
<h4 id="实现代码-部分-4"><a href="#实现代码-部分-4" class="headerlink" title="实现代码(部分)"></a>实现代码(部分)</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dropout, Dense, LSTM</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    LSTM(<span class="number">80</span>, return_sequences=<span class="literal">True</span>),</span><br><span class="line">    Dropout(<span class="number">0.2</span>),</span><br><span class="line">    LSTM(<span class="number">100</span>),</span><br><span class="line">    Dropout(<span class="number">0.2</span>),</span><br><span class="line">    Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h3 id="GRU网络"><a href="#GRU网络" class="headerlink" title="GRU网络"></a>GRU网络</h3><p>简化过后的LSTM网络，融合了长期记忆与短期记忆</p>
<h4 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h4><p><img src="https://i.loli.net/2020/12/23/2pmQUrVJ96hPbRL.png" alt="image-20201223212810181"></p>
<p>实现方法</p>
<p><img src="https://i.loli.net/2020/12/23/QmLoOwrtcKBqb2X.png" alt="image-20201223213813845"></p>
<h4 id="实现代码-部分-5"><a href="#实现代码-部分-5" class="headerlink" title="实现代码(部分)"></a>实现代码(部分)</h4><p>与LSTM相似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dropout, Dense, LSTM</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    GRU(<span class="number">80</span>, return_sequences=<span class="literal">True</span>),</span><br><span class="line">    Dropout(<span class="number">0.2</span>),</span><br><span class="line">    GRU(<span class="number">100</span>),</span><br><span class="line">    Dropout(<span class="number">0.2</span>),</span><br><span class="line">    Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h2 id="其他神经网络"><a href="#其他神经网络" class="headerlink" title="其他神经网络"></a>其他神经网络</h2><p>如深度置信神经网络DBN、生成对抗网络GAN等</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="prev" title="数据分析">
      <i class="fa fa-chevron-left"></i> 数据分析
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/python%E7%88%AC%E8%99%AB/" rel="next" title="Python爬虫">
      Python爬虫 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensor%E6%95%B0%E6%8D%AE"><span class="nav-number">1.</span> <span class="nav-text">Tensor数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAtensor"><span class="nav-number">1.1.</span> <span class="nav-text">创建tensor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="nav-number">1.2.</span> <span class="nav-text">常用函数</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#axis"><span class="nav-number">1.2.0.0.1.</span> <span class="nav-text">axis</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.3.</span> <span class="nav-text">获取数据集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#numpy%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="nav-number">2.</span> <span class="nav-text">numpy常用函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.</span> <span class="nav-text">神经网络实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%87%E6%95%B0%E8%A1%B0%E5%87%8F%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="nav-number">3.1.</span> <span class="nav-text">指数衰减学习率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.</span> <span class="nav-text">激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#relu%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.1.</span> <span class="nav-text">relu函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sigmoid%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.2.</span> <span class="nav-text">sigmoid函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tanh%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.3.</span> <span class="nav-text">tanh函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#leak-relu%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.4.</span> <span class="nav-text">leak relu函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.2.5.</span> <span class="nav-text">代码实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.3.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">3.3.1.</span> <span class="nav-text">正则化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">3.4.</span> <span class="nav-text">神经网络参数优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SGD"><span class="nav-number">3.4.1.</span> <span class="nav-text">SGD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SGDM"><span class="nav-number">3.4.2.</span> <span class="nav-text">SGDM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adagrad"><span class="nav-number">3.4.3.</span> <span class="nav-text">Adagrad</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RMSProp"><span class="nav-number">3.4.4.</span> <span class="nav-text">RMSProp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adam"><span class="nav-number">3.4.5.</span> <span class="nav-text">Adam</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C"><span class="nav-number">4.</span> <span class="nav-text">全连接网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E6%8F%8F%E8%BF%B0"><span class="nav-number">4.1.</span> <span class="nav-text">方法描述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#model-tf-keras-models-Sequential"><span class="nav-number">4.1.1.</span> <span class="nav-text">model&#x3D;tf.keras.models.Sequential</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#compile"><span class="nav-number">4.1.1.1.</span> <span class="nav-text">compile</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#fit"><span class="nav-number">4.1.1.2.</span> <span class="nav-text">fit</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#summary"><span class="nav-number">4.1.1.3.</span> <span class="nav-text">summary</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-1"><span class="nav-number">4.1.1.4.</span> <span class="nav-text">代码实现</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#class-MyModel-Model-model-MyModel"><span class="nav-number">4.1.2.</span> <span class="nav-text">class MyModel(Model) model&#x3D;MyModel</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-2"><span class="nav-number">4.1.2.1.</span> <span class="nav-text">代码实现</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mnist%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.1.3.</span> <span class="nav-text">mnist数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.1.3.1.</span> <span class="nav-text">查看数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sequential%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.1.3.2.</span> <span class="nav-text">Sequential实现</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89class%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.1.3.3.</span> <span class="nav-text">自定义class实现</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fashion%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.1.4.</span> <span class="nav-text">fashion数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Sequential%E5%AE%9E%E7%8E%B0-1"><span class="nav-number">4.1.4.1.</span> <span class="nav-text">Sequential实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%85%E6%96%B9%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">补充方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%88%B6%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.2.1.</span> <span class="nav-text">自制数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E9%83%A8%E5%88%86"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">实现代码(部分)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="nav-number">4.2.2.</span> <span class="nav-text">数据增强</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#fit-1"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">fit</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#flow"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">flow</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E9%83%A8%E5%88%86-1"><span class="nav-number">4.2.2.3.</span> <span class="nav-text">实现代码(部分)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%AD%E7%82%B9%E7%BB%AD%E8%AE%AD"><span class="nav-number">4.2.3.</span> <span class="nav-text">断点续训</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81"><span class="nav-number">4.2.3.1.</span> <span class="nav-text">实现代码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E6%8F%90%E5%8F%96"><span class="nav-number">4.2.4.</span> <span class="nav-text">参数提取</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E9%83%A8%E5%88%86-2"><span class="nav-number">4.2.4.1.</span> <span class="nav-text">实现代码(部分)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#acc-loss%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">4.2.5.</span> <span class="nav-text">acc&#x2F;loss可视化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E9%A2%84%E6%B5%8B"><span class="nav-number">4.2.6.</span> <span class="nav-text">实现预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E9%83%A8%E5%88%86-3"><span class="nav-number">4.2.6.1.</span> <span class="nav-text">实现代码(部分)</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">5.</span> <span class="nav-text">卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">5.1.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="nav-number">5.1.1.</span> <span class="nav-text">卷积核</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%84%9F%E5%8F%97%E9%87%8E"><span class="nav-number">5.1.2.</span> <span class="nav-text">感受野</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E9%9B%B6%E5%A1%AB%E5%85%85"><span class="nav-number">5.1.3.</span> <span class="nav-text">全零填充</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">5.1.4.</span> <span class="nav-text">实现卷积层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96BN"><span class="nav-number">5.1.5.</span> <span class="nav-text">批标准化BN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96"><span class="nav-number">5.1.6.</span> <span class="nav-text">池化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%88%8D%E5%BC%83"><span class="nav-number">5.1.7.</span> <span class="nav-text">舍弃</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.2.</span> <span class="nav-text">总体实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.2.1.</span> <span class="nav-text">自定义模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="nav-number">5.3.</span> <span class="nav-text">经典卷积网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LeNet"><span class="nav-number">5.3.1.</span> <span class="nav-text">LeNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">5.3.1.1.</span> <span class="nav-text">模型代码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AlexNet"><span class="nav-number">5.3.2.</span> <span class="nav-text">AlexNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81-1"><span class="nav-number">5.3.2.1.</span> <span class="nav-text">模型代码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#VGGNet"><span class="nav-number">5.3.3.</span> <span class="nav-text">VGGNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#16%E5%B1%82VGGNet%E5%AE%9E%E4%BE%8B"><span class="nav-number">5.3.3.1.</span> <span class="nav-text">16层VGGNet实例</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#InceptionNet"><span class="nav-number">5.3.4.</span> <span class="nav-text">InceptionNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B2%BE%E7%AE%80%E7%89%88%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">5.3.4.1.</span> <span class="nav-text">精简版模型代码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ResNet"><span class="nav-number">5.3.5.</span> <span class="nav-text">ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81-2"><span class="nav-number">5.3.5.1.</span> <span class="nav-text">模型代码</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">6.</span> <span class="nav-text">循环神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-1"><span class="nav-number">6.1.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E6%A0%B8"><span class="nav-number">6.1.1.</span> <span class="nav-text">循环核</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E6%A0%B8%E6%97%B6%E9%97%B4%E6%AD%A5%E5%B1%95%E5%BC%80"><span class="nav-number">6.1.1.0.1.</span> <span class="nav-text">循环核时间步展开</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E8%AE%A1%E7%AE%97%E5%B1%82"><span class="nav-number">6.1.1.0.2.</span> <span class="nav-text">循环计算层</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E5%BE%AA%E7%8E%AF%E8%AE%A1%E7%AE%97%E5%B1%82"><span class="nav-number">6.1.2.</span> <span class="nav-text">实现循环计算层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="nav-number">6.1.3.</span> <span class="nav-text">循环计算过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#one-hot%E5%AE%9E%E7%8E%B0%E9%A2%84%E6%B5%8B%E5%AD%97%E6%AF%8D"><span class="nav-number">6.2.</span> <span class="nav-text">one-hot实现预测字母</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Embedding%E5%AE%9E%E7%8E%B0%E9%A2%84%E6%B5%8B%E5%AD%97%E6%AF%8D"><span class="nav-number">6.3.</span> <span class="nav-text">Embedding实现预测字母</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%95%BF%E7%9F%AD%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C-LSTM"><span class="nav-number">6.4.</span> <span class="nav-text">长短记忆网络(LSTM)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E9%83%A8%E5%88%86-4"><span class="nav-number">6.4.1.</span> <span class="nav-text">实现代码(部分)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GRU%E7%BD%91%E7%BB%9C"><span class="nav-number">6.5.</span> <span class="nav-text">GRU网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="nav-number">6.5.1.</span> <span class="nav-text">计算过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-%E9%83%A8%E5%88%86-5"><span class="nav-number">6.5.2.</span> <span class="nav-text">实现代码(部分)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">7.</span> <span class="nav-text">其他神经网络</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lan5th"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">lan5th</p>
  <div class="site-description" itemprop="description">practise more</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/lan5th" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lan5th" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.bilibili.com/video/BV1Lt411R78H?p=1" title="https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1Lt411R78H?p&#x3D;1" rel="noopener" target="_blank">主题教程</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://lixint.github.io/" title="https:&#x2F;&#x2F;lixint.github.io&#x2F;" rel="noopener" target="_blank">教程博客</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lan5th</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">482k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:18</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
