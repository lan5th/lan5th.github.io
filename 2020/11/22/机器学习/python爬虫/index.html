<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lan5th.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="爬虫概念：通过编写程序模拟浏览器上网，然后去互联网上抓取数据">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫">
<meta property="og:url" content="http://lan5th.github.io/2020/11/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Lzone">
<meta property="og:description" content="爬虫概念：通过编写程序模拟浏览器上网，然后去互联网上抓取数据">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/11/22/5Ic2VzUetnmqZGa.png">
<meta property="og:image" content="https://i.loli.net/2020/11/22/fLtRyiXJhq4ZPpl.png">
<meta property="og:image" content="https://i.loli.net/2020/11/22/pFTqKX6LksEt15R.png">
<meta property="og:image" content="https://i.loli.net/2020/11/22/usE12O95JZtYimV.png">
<meta property="og:image" content="https://i.loli.net/2020/11/22/Y5blVtozsfCQknj.png">
<meta property="article:published_time" content="2020-11-22T02:32:46.078Z">
<meta property="article:modified_time" content="2021-02-14T12:10:56.308Z">
<meta property="article:author" content="lan5th">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/11/22/5Ic2VzUetnmqZGa.png">

<link rel="canonical" href="http://lan5th.github.io/2020/11/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/python%E7%88%AC%E8%99%AB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Python爬虫 | Lzone</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  
  
    <script
      src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4="
      crossorigin="anonymous"></script>
    <script src="/js/cursor/text.js"></script>
  

<link rel="alternate" href="/atom.xml" title="Lzone" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzone</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">always be doing</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/lan5th" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://lan5th.github.io/2020/11/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/python%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="lan5th">
      <meta itemprop="description" content="practise more">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzone">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python爬虫
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-22 10:32:46" itemprop="dateCreated datePublished" datetime="2020-11-22T10:32:46+08:00">2020-11-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-02-14 20:10:56" itemprop="dateModified" datetime="2021-02-14T20:10:56+08:00">2021-02-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>爬虫概念：通过编写程序模拟浏览器上网，然后去互联网上抓取数据</p>
<a id="more"></a>

<p>通用爬虫：抓取系统的组成部分，抓取一整张页面数据</p>
<p>聚焦爬虫：建立在通用爬虫基础上，抓取页面中特定内容</p>
<p>增量式爬虫：检测网站中数据更新情况，只抓取最新更新的数据</p>
<p>反爬机制/反反爬策略</p>
<p>robots.txt协议：”域名/robots.txt”口头约定是否允许爬取数据</p>
<h2 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h2><p>超文本传输协议</p>
<h3 id="常用请求头信息"><a href="#常用请求头信息" class="headerlink" title="常用请求头信息"></a>常用请求头信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User-Agent										请求载体的身份标识</span><br><span class="line">Connection										请求完毕后断开或保持连接</span><br></pre></td></tr></table></figure>

<h3 id="常用响应头信息"><a href="#常用响应头信息" class="headerlink" title="常用响应头信息"></a>常用响应头信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type									服务器响应客户端数据类型</span><br></pre></td></tr></table></figure>

<h2 id="https协议"><a href="#https协议" class="headerlink" title="https协议"></a>https协议</h2><p>安全的超文本传输协议（数据加密），采用证书密钥加密</p>
<h3 id="加密方式"><a href="#加密方式" class="headerlink" title="加密方式"></a>加密方式</h3><h4 id="对称密钥加密"><a href="#对称密钥加密" class="headerlink" title="对称密钥加密"></a>对称密钥加密</h4><p><img src="https://i.loli.net/2020/11/22/5Ic2VzUetnmqZGa.png" alt="img"></p>
<p>存在安全隐患</p>
<h4 id="非对称密钥加密"><a href="#非对称密钥加密" class="headerlink" title="非对称密钥加密"></a>非对称密钥加密</h4><p><img src="https://i.loli.net/2020/11/22/fLtRyiXJhq4ZPpl.png"></p>
<p>效率较低，存在安全隐患</p>
<h4 id="证书密钥加密"><a href="#证书密钥加密" class="headerlink" title="证书密钥加密"></a>证书密钥加密</h4><p><img src="https://i.loli.net/2020/11/22/pFTqKX6LksEt15R.png" alt="img"></p>
<h2 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h2><h3 id="urllib模块"><a href="#urllib模块" class="headerlink" title="urllib模块"></a>urllib模块</h3><h3 id="requests模块-1"><a href="#requests模块-1" class="headerlink" title="requests模块"></a>requests模块</h3><p>作用：模拟浏览器发请求</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">requests.get(url&#x3D;, params&#x3D;, headers&#x3D;)				给params传入字典可以动态拼接成url参数</span><br><span class="line">												给headers传入字典可以伪装成某一浏览器</span><br><span class="line">requests.post(url&#x3D;, params&#x3D;, headers&#x3D;)				post请求与之类似</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 指定url</span></span><br><span class="line">    url = <span class="string">&#x27;https://www.sogou.com/&#x27;</span></span><br><span class="line">    <span class="comment"># 发起请求</span></span><br><span class="line">    <span class="comment"># get方法返回一个响应对象</span></span><br><span class="line">    response = requests.get(url=url)</span><br><span class="line">    <span class="comment"># 获取响应数据.text返回字符串型数据</span></span><br><span class="line">    content = response.text</span><br><span class="line">    <span class="comment"># 持久化存储</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">&#x27;./dataset/sougou.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(content)</span><br></pre></td></tr></table></figure>

<h4 id="UA检测：一种反爬机制"><a href="#UA检测：一种反爬机制" class="headerlink" title="UA检测：一种反爬机制"></a>UA检测：一种反爬机制</h4><p>门户网站服务器检测请求数据的UA标识，若为爬虫，服务器可能会拒绝该次请求。</p>
<h4 id="UA伪装：对应的反反爬策略"><a href="#UA伪装：对应的反反爬策略" class="headerlink" title="UA伪装：对应的反反爬策略"></a>UA伪装：对应的反反爬策略</h4><p>伪装成为某一浏览器</p>
<p>将headers字典传入requests的headers参数中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers &#x3D; &#123;</span><br><span class="line">	&#39;User-Agent&#39;:&#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.66 Safari&#x2F;537.36 Edg&#x2F;87.0.664.41&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实例1：模拟搜索引擎</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://www.sogou.com/web&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36 Edg/87.0.664.41&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    kw = input(<span class="string">&#x27;Enter a word:&#x27;</span>)</span><br><span class="line">    param = &#123;</span><br><span class="line">        <span class="string">&#x27;query&#x27;</span>: kw</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url=url, params=param, headers=headers)</span><br><span class="line">    content = response.text</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">&#x27;./dataset/&#x27;</span>+kw+<span class="string">&#x27;.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(content)</span><br></pre></td></tr></table></figure>

<p>实例2：爬取豆瓣网电影列表</p>
<p>通过ajax动态请求查看数据请求细节</p>
<p><img src="https://i.loli.net/2020/11/22/usE12O95JZtYimV.png" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://movie.douban.com/j/chart/top_list&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36 Edg/87.0.664.41&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    param = &#123;</span><br><span class="line">        <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;24&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;interval_id&#x27;</span>: <span class="string">&#x27;100:90&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;action&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;start&#x27;</span>: <span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;limit&#x27;</span>: <span class="string">&#x27;300&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url=url, params=param, headers=headers)</span><br><span class="line">    data = response.json()</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">&#x27;./dataset/douban.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        json.dump(data, fp=fp, ensure_ascii=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h2><p>聚焦爬虫</p>
<p>流程：指定url；发起请求；获取响应数据；数据解析；持久化存储</p>
<h3 id="正则"><a href="#正则" class="headerlink" title="正则"></a>正则</h3><p>多语言适用</p>
<p>实例：爬取糗图网图片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 通过os创建文件夹保存所有图片</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;../dataset/pics&#x27;</span>):</span><br><span class="line">        os.mkdir(<span class="string">&#x27;../dataset/pics&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    url = <span class="string">&#x27;https://www.qiushibaike.com/imgrank/&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36 Edg/87.0.664.41&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 获取整张页面数据</span></span><br><span class="line">    page_text = requests.get(url=url, headers=headers).text</span><br><span class="line">    <span class="comment"># 使用聚焦爬虫（正则）将页面所有图片进行提取</span></span><br><span class="line">    ex = <span class="string">&#x27;&lt;div class=&quot;thumb&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; alt.*?&lt;/div&gt;&#x27;</span></span><br><span class="line">    img_src_list = re.findall(ex, page_text, re.S)</span><br><span class="line">    <span class="keyword">for</span> src <span class="keyword">in</span> img_src_list:</span><br><span class="line">        src = <span class="string">&#x27;https:&#x27;</span> + src</span><br><span class="line">        <span class="comment"># 获取二进制数据</span></span><br><span class="line">        img_data = requests.get(url=src, headers=headers).content</span><br><span class="line">        img_name = src.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">-1</span>]</span><br><span class="line">        img_path = <span class="string">&#x27;../dataset/pics&#x27;</span>+img_name</span><br><span class="line">        <span class="comment"># 以二进制类型存储</span></span><br><span class="line">        <span class="keyword">with</span> open(img_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            fp.write(img_data)</span><br><span class="line">        print(img_name,<span class="string">&#x27;下载成功！&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>关于re的补充内容</p>
<p><img src="https://i.loli.net/2020/11/22/Y5blVtozsfCQknj.png" alt="img"></p>
<h3 id="bs4"><a href="#bs4" class="headerlink" title="bs4"></a>bs4</h3><p>python独有的方法</p>
<p>需要安装bs4,lxml</p>
<ol>
<li><p>实例化一个BeautifulSoup对象，并将页面源码数据加载到该对象中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fp = open(<span class="string">&#x27;../dataset/test.html&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment">#使用lxml对本地文件进行解析</span></span><br><span class="line">    BeautifulSoup.(fp, <span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">page_text = response.text</span><br><span class="line"><span class="comment">#使用lxml直接对网络数据进行解析</span></span><br><span class="line">soup = BeautifulSoup(page_text, <span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过调用BeautifulSoup内置属性或方法进行标签定位和数据提取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">soup.标签名									获取第一个该标签的内容</span><br><span class="line">soup.find(&#39;标签名&#39;)							 同上</span><br><span class="line">soup.find(&#39;标签名&#39;, class_&#x2F;id&#x2F;attr&#x3D;&#39;&#39;)			   指定属性查找</span><br><span class="line">soup.find_all()								   符合要求的所有标签</span><br><span class="line">soup.select(&#39;&#39;)								   可以使用某种选择器，返回列表</span><br><span class="line">soup.select(&#39;.tang &gt; ul &gt; li &gt;a&#39;)				层级选择器 &#39;&gt;&#39;表示一个层级</span><br><span class="line">soup.select(&#39;.tang &gt; ul a&#39;)						层级选择器 &#39; &#39;表示多个层级</span><br></pre></td></tr></table></figure>

<p>获取标签之间的文本数据/属性值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sp &#x3D; soup.select(&#39;.tang &gt; ul &gt; li&#39;)</span><br><span class="line">sp[0].a.text&#x2F;string&#x2F;get_text()					获取a标签文本数据</span><br><span class="line">text&#x2F;get_text()获取所有文本(可以跨越层级)	string仅获取该标签直系文本内容</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup.a[&#39;href&#39;]									获取a标签中href属性值</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>实例：获取三国演义文本(已失效)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> _name_<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	<span class="comment"># 对首页的页面数据进行爬取</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">	<span class="string">&#x27;User-Agent&#x27;</span> : (...)</span><br><span class="line">    &#125;</span><br><span class="line">	url = <span class="string">&#x27;http://www.shicimingju.com/book/sanguoyanyi.html&#x27;</span></span><br><span class="line">    page_text = requests.get(url=url,headers=headers)</span><br><span class="line">	<span class="comment"># 在首页史解析出意节的标题和详情页的ucl</span></span><br><span class="line">	<span class="comment"># 实例化BeautifulS.oup对象..需要将页面源码数据加戴到该对象虫</span></span><br><span class="line">	soup = BeautifulSoup(page_text, <span class="string">&#x27;lxml &#x27;</span>)</span><br><span class="line">	<span class="comment"># 解析章节标题和详情页的url</span></span><br><span class="line">	li_list = soup.select( <span class="string">&#x27;.book-mulu &gt; ul &gt; li&#x27;</span>)</span><br><span class="line">    fp = open( <span class="string">&#x27;./sanguo.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">		title = li.a.string</span><br><span class="line">		detail_url = <span class="string">&#x27;http://www.shicimingju. com&#x27;</span>+li.a[ <span class="string">&#x27; href &#x27;</span>]</span><br><span class="line">    	<span class="comment"># 对详情页发起请求..解析出竟节内容</span></span><br><span class="line">		detail_page_text = requests.get(url=detail_url,headers=headers).text</span><br><span class="line">    	<span class="comment"># 解析出详情页史相关的意节内容</span></span><br><span class="line">		detail_soup = BeautifulSoup(detail_page_text, <span class="string">&#x27;lxml &#x27;</span>)</span><br><span class="line">		div_tag = detail_soup.find( <span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;chapter_content&#x27;</span>)</span><br><span class="line">		<span class="comment"># 解析到了意节的内察</span></span><br><span class="line">		content = div_tag.text</span><br><span class="line">		fp.write(title+<span class="string">&#x27;:&#x27;</span>+content+<span class="string">&#x27;\n&#x27;</span>)print(title <span class="string">&#x27;爬取成功!!!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="xpath"><a href="#xpath" class="headerlink" title="xpath"></a>xpath</h3><p>便捷高效，多语言通用性</p>
<p>只需要安装lxml</p>
<ol>
<li><p>实例化一个etree对象，并将页面源码数据加载到该对象中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">etree.parse(filePath)								本地文件</span><br><span class="line">etree.HTML(&#39;page_text&#39;)								源码数据</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过调用etree对象xpath方法结合xpath表达式进行标签定位和数据提取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tree &#x3D; etree.parse(filePath)</span><br><span class="line">   tree.xpath(&#39;&#x2F;html&#x2F;head&#x2F;title&#39;)						从外向内定位，返回element对象的列表</span><br></pre></td></tr></table></figure>
</li>
<li><p>xpath表达式详解</p>
<p>下列表达式返回值都为列表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;html&#x2F;div&#x2F;li&#x2F;a									&#39;&#x2F;&#39;:一个层级</span><br><span class="line">&#x2F;html&#x2F;&#x2F;a 或 &#x2F;&#x2F;a									&#39;&#x2F;&#x2F;&#39;:多个层级</span><br><span class="line">&#x2F;&#x2F;div[@class&#x3D;&quot;song&quot;]							属性定位</span><br><span class="line">&#x2F;&#x2F;div[@class&#x3D;&quot;song&quot;]&#x2F;p[3]						对p标签进行索引(索引从1开始)</span><br><span class="line">&#x2F;&#x2F;div&#x2F;text()									获取文本内容(只能获取本层子内容)</span><br><span class="line">&#x2F;&#x2F;div&#x2F;&#x2F;text()									获取文本内容(全部内容，可传递)</span><br><span class="line">&#x2F;&#x2F;div[@class&#x3D;&quot;song&quot;]&#x2F;img&#x2F;@attr					 获取attr属性的内容</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>实例：获取58同城房产信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://bj.58.com/ershoufang/&#x27;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36 Edg/87.0.664.41&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 获取整张页面数据</span></span><br><span class="line">    page_text = requests.get(url=url, headers=headers).text</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    li_list = tree.xpath(<span class="string">&#x27;//ul[@class=&quot;house-list-wrap&quot;]/li&#x27;</span>)</span><br><span class="line">    <span class="comment">#数据解析</span></span><br><span class="line">    fp = open(<span class="string">&#x27;../dataset/58.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        <span class="comment">#局部解析,&#x27;./&#x27;表示本级目录</span></span><br><span class="line">        title = li.xpath(<span class="string">&#x27;./div[2]/h2/a/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        print(title)</span><br><span class="line">        fp.write(title+<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="反爬机制"><a href="#反爬机制" class="headerlink" title="反爬机制"></a>反爬机制</h2><h3 id="验证码"><a href="#验证码" class="headerlink" title="验证码"></a>验证码</h3><p>第三方自动识别</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow/" rel="prev" title="Tensorflow2.0">
      <i class="fa fa-chevron-left"></i> Tensorflow2.0
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/12/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Sklearn/" rel="next" title="Sklearn学习">
      Sklearn学习 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#http%E5%8D%8F%E8%AE%AE"><span class="nav-number">1.</span> <span class="nav-text">http协议</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E8%AF%B7%E6%B1%82%E5%A4%B4%E4%BF%A1%E6%81%AF"><span class="nav-number">1.1.</span> <span class="nav-text">常用请求头信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%93%8D%E5%BA%94%E5%A4%B4%E4%BF%A1%E6%81%AF"><span class="nav-number">1.2.</span> <span class="nav-text">常用响应头信息</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#https%E5%8D%8F%E8%AE%AE"><span class="nav-number">2.</span> <span class="nav-text">https协议</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A0%E5%AF%86%E6%96%B9%E5%BC%8F"><span class="nav-number">2.1.</span> <span class="nav-text">加密方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86"><span class="nav-number">2.1.1.</span> <span class="nav-text">对称密钥加密</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86"><span class="nav-number">2.1.2.</span> <span class="nav-text">非对称密钥加密</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%81%E4%B9%A6%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86"><span class="nav-number">2.1.3.</span> <span class="nav-text">证书密钥加密</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#requests%E6%A8%A1%E5%9D%97"><span class="nav-number">3.</span> <span class="nav-text">requests模块</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#urllib%E6%A8%A1%E5%9D%97"><span class="nav-number">3.1.</span> <span class="nav-text">urllib模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#requests%E6%A8%A1%E5%9D%97-1"><span class="nav-number">3.2.</span> <span class="nav-text">requests模块</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#UA%E6%A3%80%E6%B5%8B%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%8F%8D%E7%88%AC%E6%9C%BA%E5%88%B6"><span class="nav-number">3.2.1.</span> <span class="nav-text">UA检测：一种反爬机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#UA%E4%BC%AA%E8%A3%85%EF%BC%9A%E5%AF%B9%E5%BA%94%E7%9A%84%E5%8F%8D%E5%8F%8D%E7%88%AC%E7%AD%96%E7%95%A5"><span class="nav-number">3.2.2.</span> <span class="nav-text">UA伪装：对应的反反爬策略</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90"><span class="nav-number">4.</span> <span class="nav-text">数据解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%88%99"><span class="nav-number">4.1.</span> <span class="nav-text">正则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bs4"><span class="nav-number">4.2.</span> <span class="nav-text">bs4</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xpath"><span class="nav-number">4.3.</span> <span class="nav-text">xpath</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%8D%E7%88%AC%E6%9C%BA%E5%88%B6"><span class="nav-number">5.</span> <span class="nav-text">反爬机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E7%A0%81"><span class="nav-number">5.1.</span> <span class="nav-text">验证码</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lan5th"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">lan5th</p>
  <div class="site-description" itemprop="description">practise more</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/lan5th" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lan5th" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.bilibili.com/video/BV1Lt411R78H?p=1" title="https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1Lt411R78H?p&#x3D;1" rel="noopener" target="_blank">主题教程</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://lixint.github.io/" title="https:&#x2F;&#x2F;lixint.github.io&#x2F;" rel="noopener" target="_blank">教程博客</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lan5th</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">490k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:26</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
